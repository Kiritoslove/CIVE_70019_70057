{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bradleywjenks/CIVE_70019_70057/blob/main/notebooks/coursework_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3ea0ffc",
      "metadata": {
        "id": "c3ea0ffc"
      },
      "source": [
        "# Coursework: Hydraulic model calibration (Part 2)\n",
        "\n",
        "\n",
        "### CIVE 70019/70057\n",
        "Department of Civil and Environmental Engineering, Imperial College London"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eebea76",
      "metadata": {
        "id": "5eebea76"
      },
      "source": [
        "You have been tasked with the evaluation and calibration of the hydraulic model of EXNING, a district metered area (DMA) in Anglian Water's (AW) water distribution network. To achieve this, you have been provided:\n",
        "* a hydraulic model of the EXNING DMA, in use by Anglian Water in early 2019 (no record of recent calibration),\n",
        "* pipe groups (based on material & age) and corresponding ranges of H-W coefficients,\n",
        "* hourly loading conditions (demands, reservoir heads) and head measurements covering a period of 4 days.\n",
        "\n",
        "The objective of the coursework is to prepare a short calibration report for AW by completing the tasks below and answering the questions (max. 100-150 words per question) based on your results. Don't forget to include titles, labels and legends in your plots, and watch for significant figures in your reporting!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ecf250d",
      "metadata": {
        "id": "1ecf250d"
      },
      "source": [
        "You have been provided the following information about EXNING:\n",
        "* EXNING is part of a larger system of cascading DMAs: EXNING is fed by the NEWSEV DMA and feeds into the BURWEL DMA.\n",
        "* According to AW's existing records, EXNING contains mostly old, cast iron pipes.\n",
        "* The \"reservoir\" head  and total demand of EXNING are derived from flow and pressure sensors at the DMA inlet (& outlet).\n",
        "* Node elevations have been updated in the provided model following a GPS survey of sensor locations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7aeb130",
      "metadata": {
        "id": "e7aeb130"
      },
      "source": [
        "First, we must clone the GitHub repository and install dependencies (only run this once)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "XUkd0ndZ-Fy_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUkd0ndZ-Fy_",
        "outputId": "b2458d22-702a-48e6-fa29-270e9a29f3ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'CIVE_70019_70057'...\n",
            "remote: Enumerating objects: 723, done.\u001b[K\n",
            "remote: Counting objects: 100% (473/473), done.\u001b[K\n",
            "remote: Compressing objects: 100% (204/204), done.\u001b[K\n",
            "remote: Total 723 (delta 294), reused 431 (delta 269), pack-reused 250 (from 1)\u001b[K\n",
            "Receiving objects: 100% (723/723), 10.87 MiB | 6.12 MiB/s, done.\n",
            "Resolving deltas: 100% (444/444), done.\n",
            "Collecting wntr\n",
            "  Downloading wntr-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.10/dist-packages (from wntr) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from wntr) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from wntr) (3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from wntr) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from wntr) (3.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wntr) (71.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wntr) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wntr) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wntr) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wntr) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wntr) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wntr) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wntr) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wntr) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->wntr) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->wntr) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->wntr) (1.16.0)\n",
            "Downloading wntr-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wntr\n",
            "Successfully installed wntr-1.2.0\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from cvxpy) (0.6.7.post0)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy) (2.0.14)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from cvxpy) (0.9.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.10/dist-packages (from cvxpy) (3.2.7)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from cvxpy) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from cvxpy) (1.13.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.6.2->cvxpy) (0.1.7.post4)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libamd2 libbtf1 libcamd2 libccolamd2 libcholmod3 libcolamd2 libcxsparse3 libgraphblas-dev\n",
            "  libgraphblas6 libklu1 libldl2 libmetis5 libmongoose2 librbio2 libsliplu1 libspqr2\n",
            "  libsuitesparseconfig5 libumfpack5\n",
            "The following NEW packages will be installed:\n",
            "  libamd2 libbtf1 libcamd2 libccolamd2 libcholmod3 libcolamd2 libcxsparse3 libgraphblas-dev\n",
            "  libgraphblas6 libklu1 libldl2 libmetis5 libmongoose2 librbio2 libsliplu1 libspqr2\n",
            "  libsuitesparse-dev libsuitesparseconfig5 libumfpack5\n",
            "0 upgraded, 19 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 22.4 MB of archives.\n",
            "After this operation, 169 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsuitesparseconfig5 amd64 1:5.10.1+dfsg-4build1 [10.4 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libamd2 amd64 1:5.10.1+dfsg-4build1 [21.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libbtf1 amd64 1:5.10.1+dfsg-4build1 [12.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcamd2 amd64 1:5.10.1+dfsg-4build1 [23.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libccolamd2 amd64 1:5.10.1+dfsg-4build1 [25.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libcolamd2 amd64 1:5.10.1+dfsg-4build1 [18.0 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmetis5 amd64 5.1.0.dfsg-7build2 [181 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcholmod3 amd64 1:5.10.1+dfsg-4build1 [346 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcxsparse3 amd64 1:5.10.1+dfsg-4build1 [70.8 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libgraphblas6 amd64 6.1.4+dfsg-2 [20.1 MB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libgraphblas-dev amd64 6.1.4+dfsg-2 [54.4 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libklu1 amd64 1:5.10.1+dfsg-4build1 [77.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libldl2 amd64 1:5.10.1+dfsg-4build1 [11.7 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmongoose2 amd64 1:5.10.1+dfsg-4build1 [33.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/universe amd64 librbio2 amd64 1:5.10.1+dfsg-4build1 [26.6 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libsliplu1 amd64 1:5.10.1+dfsg-4build1 [37.1 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libspqr2 amd64 1:5.10.1+dfsg-4build1 [71.6 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libumfpack5 amd64 1:5.10.1+dfsg-4build1 [250 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libsuitesparse-dev amd64 1:5.10.1+dfsg-4build1 [1,058 kB]\n",
            "Fetched 22.4 MB in 2s (13.7 MB/s)\n",
            "Selecting previously unselected package libsuitesparseconfig5:amd64.\n",
            "(Reading database ... 123621 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libsuitesparseconfig5_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libsuitesparseconfig5:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libamd2:amd64.\n",
            "Preparing to unpack .../01-libamd2_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libamd2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libbtf1:amd64.\n",
            "Preparing to unpack .../02-libbtf1_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libbtf1:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libcamd2:amd64.\n",
            "Preparing to unpack .../03-libcamd2_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libcamd2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libccolamd2:amd64.\n",
            "Preparing to unpack .../04-libccolamd2_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libccolamd2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libcolamd2:amd64.\n",
            "Preparing to unpack .../05-libcolamd2_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libcolamd2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libmetis5:amd64.\n",
            "Preparing to unpack .../06-libmetis5_5.1.0.dfsg-7build2_amd64.deb ...\n",
            "Unpacking libmetis5:amd64 (5.1.0.dfsg-7build2) ...\n",
            "Selecting previously unselected package libcholmod3:amd64.\n",
            "Preparing to unpack .../07-libcholmod3_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libcholmod3:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libcxsparse3:amd64.\n",
            "Preparing to unpack .../08-libcxsparse3_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libcxsparse3:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libgraphblas6:amd64.\n",
            "Preparing to unpack .../09-libgraphblas6_6.1.4+dfsg-2_amd64.deb ...\n",
            "Unpacking libgraphblas6:amd64 (6.1.4+dfsg-2) ...\n",
            "Selecting previously unselected package libgraphblas-dev:amd64.\n",
            "Preparing to unpack .../10-libgraphblas-dev_6.1.4+dfsg-2_amd64.deb ...\n",
            "Unpacking libgraphblas-dev:amd64 (6.1.4+dfsg-2) ...\n",
            "Selecting previously unselected package libklu1:amd64.\n",
            "Preparing to unpack .../11-libklu1_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libklu1:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libldl2:amd64.\n",
            "Preparing to unpack .../12-libldl2_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libldl2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libmongoose2:amd64.\n",
            "Preparing to unpack .../13-libmongoose2_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libmongoose2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package librbio2:amd64.\n",
            "Preparing to unpack .../14-librbio2_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking librbio2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libsliplu1:amd64.\n",
            "Preparing to unpack .../15-libsliplu1_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libsliplu1:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libspqr2:amd64.\n",
            "Preparing to unpack .../16-libspqr2_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libspqr2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libumfpack5:amd64.\n",
            "Preparing to unpack .../17-libumfpack5_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libumfpack5:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libsuitesparse-dev:amd64.\n",
            "Preparing to unpack .../18-libsuitesparse-dev_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libsuitesparse-dev:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libgraphblas6:amd64 (6.1.4+dfsg-2) ...\n",
            "Setting up libldl2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libmetis5:amd64 (5.1.0.dfsg-7build2) ...\n",
            "Setting up libbtf1:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libgraphblas-dev:amd64 (6.1.4+dfsg-2) ...\n",
            "Setting up libcxsparse3:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libsuitesparseconfig5:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up librbio2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libamd2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libcolamd2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libsliplu1:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libcamd2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libmongoose2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libklu1:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libccolamd2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libcholmod3:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libspqr2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libumfpack5:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libsuitesparse-dev:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Collecting scikit-sparse\n",
            "  Downloading scikit_sparse-0.4.15.tar.gz (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-sparse) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from scikit-sparse) (1.13.1)\n",
            "Building wheels for collected packages: scikit-sparse\n",
            "  Building wheel for scikit-sparse (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-sparse: filename=scikit_sparse-0.4.15-cp310-cp310-linux_x86_64.whl size=713882 sha256=345186adbc9e42c829c39cd79412588db1554b1021044e7cd3738edb8978a0f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/da/85/6a2a079785e6ea2e1c2f06d98eb2c74bee93601b6f648b305e\n",
            "Successfully built scikit-sparse\n",
            "Installing collected packages: scikit-sparse\n",
            "Successfully installed scikit-sparse-0.4.15\n"
          ]
        }
      ],
      "source": [
        "# run this cell once\n",
        "import sys\n",
        "import os\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  !git clone https://github.com/bradleywjenks/CIVE_70019_70057.git\n",
        "  !pip install wntr\n",
        "  !pip install cvxpy\n",
        "  !apt-get install libsuitesparse-dev && pip install scikit-sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "Bg3A6sO13PRH",
      "metadata": {
        "id": "Bg3A6sO13PRH"
      },
      "outputs": [],
      "source": [
        "# load packages\n",
        "import numpy as np\n",
        "from numpy import linalg as la\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import wntr\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import copy\n",
        "from datetime import datetime, timedelta\n",
        "import cvxpy as cp\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# improve matplotlib image quality\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "import matplotlib_inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Im1H-3E-2rNx",
      "metadata": {
        "id": "Im1H-3E-2rNx"
      },
      "source": [
        "### Load network properties, operational data, and functions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18ff4e16",
      "metadata": {
        "id": "18ff4e16"
      },
      "source": [
        "Load functions created in previous assignments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3b8e8f67",
      "metadata": {
        "id": "3b8e8f67"
      },
      "outputs": [],
      "source": [
        "# load functions from src folder\n",
        "if 'google.colab' in sys.modules:\n",
        "    sys.path.append('/content/CIVE_70019_70057/src/')\n",
        "    from general_functions import *\n",
        "    from hydraulic_functions import *\n",
        "else:\n",
        "    sys.path.append('/home/bradw/workspace/CIVE_70019_70057/src/')\n",
        "    from general_functions import *\n",
        "    from hydraulic_functions import *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8S6RiXY_28PC",
      "metadata": {
        "id": "8S6RiXY_28PC"
      },
      "source": [
        "Load network .inp file and operational data from the module repository's data directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "x9vbD66O22q_",
      "metadata": {
        "id": "x9vbD66O22q_"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "    # if run in Google Colab\n",
        "    data_dir = '/content/CIVE_70019_70057/data/parameter_estimation/'\n",
        "    net_dir = '/content/CIVE_70019_70057/data/networks/'\n",
        "else:\n",
        "    # replace with local directory\n",
        "    data_dir = '/home/bradw/workspace/CIVE_70019_70057/data/parameter_estimation/'\n",
        "    net_dir = '/home/bradw/workspace/CIVE_70019_70057/data/networks/'\n",
        "\n",
        "net_name = 'exning.inp'\n",
        "data_name = 'exning_coursework_dataset.npy'\n",
        "\n",
        "# load operational data\n",
        "data = np.load(os.path.join(data_dir, data_name), allow_pickle=True).item()\n",
        "h_data = data['h_data']\n",
        "sensor_idx = data['sensor_idx'] - 1 # matlab to python index offset\n",
        "d_data = data['d']\n",
        "h0_data = data['h0'].reshape(-1, 1).T\n",
        "\n",
        "# load network properties\n",
        "wdn = load_network_data(os.path.join(net_dir, net_name))\n",
        "A12 = wdn.A12\n",
        "A10 = wdn.A10\n",
        "net_info = wdn.net_info\n",
        "link_df = wdn.link_df\n",
        "node_df = wdn.node_df\n",
        "demand_df = wdn.demand_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IVw1luezmfxv",
      "metadata": {
        "id": "IVw1luezmfxv"
      },
      "source": [
        "Plot sensor nodes in network. We provide a plotting function below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ec181359",
      "metadata": {
        "id": "ec181359"
      },
      "outputs": [],
      "source": [
        "#### DO NOT CHANGE THIS ####\n",
        "# network plotting function\n",
        "def plot_network(wdn, sensor_idx, vals=None, highlight_valves=None):\n",
        "\n",
        "    # unload data\n",
        "    link_df = wdn.link_df\n",
        "    node_df = wdn.node_df\n",
        "    net_info = wdn.net_info\n",
        "    h0_df = wdn.h0_df\n",
        "\n",
        "    # draw network\n",
        "    uG = nx.from_pandas_edgelist(link_df, source='node_out', target='node_in')\n",
        "    pos = {row['node_ID']: (row['xcoord'], row['ycoord']) for _, row in node_df.iterrows()}\n",
        "    nx.draw(uG, pos, node_size=20, node_shape='o')\n",
        "\n",
        "    # draw reservoir\n",
        "    nx.draw_networkx_nodes(uG, pos, nodelist=net_info['reservoir_names'], node_size=100, node_shape='s', node_color='black')\n",
        "\n",
        "    # draw sensor nodes\n",
        "    sensor_names = [net_info['junction_names'][i] for i in sensor_idx]\n",
        "    nx.draw_networkx_nodes(uG, pos, sensor_names, node_size=100, node_shape='o', node_color='red', edgecolors='white')\n",
        "\n",
        "    # reservoir labels\n",
        "    reservoir_labels = {node: 'Reservoir' for node in net_info['reservoir_names']}\n",
        "    labels_res = nx.draw_networkx_labels(uG, pos, reservoir_labels, font_size=12, verticalalignment='top')\n",
        "    for _, label in labels_res.items():\n",
        "        label.set_y(label.get_position()[1] - 1500)\n",
        "\n",
        "    # sensor labels\n",
        "    sensor_labels = {node: str(idx+1) for (idx, node) in enumerate(sensor_names)}\n",
        "    labels_sen = nx.draw_networkx_labels(uG, pos, sensor_labels, font_size=12, verticalalignment='bottom')\n",
        "    for _, label in labels_sen.items():\n",
        "        label.set_y(label.get_position()[1] + 1000)\n",
        "\n",
        "    # plot sensor vals\n",
        "    if vals is not None:\n",
        "\n",
        "        cmap = cm.get_cmap('RdYlGn_r')\n",
        "\n",
        "        # plot residuals\n",
        "        nx.draw_networkx_nodes(uG, pos, nodelist=sensor_names, node_size=100, node_shape='o', node_color=vals, cmap=cmap, edgecolors='white')\n",
        "\n",
        "        # create color bar\n",
        "        sm = plt.cm.ScalarMappable(cmap=cmap)\n",
        "        sm.set_array(vals)\n",
        "        colorbar = plt.colorbar(sm)\n",
        "        colorbar.set_label('Mean pressure residual [m]', fontsize=12)\n",
        "\n",
        "    # highlight link\n",
        "    if highlight_valves is not None:\n",
        "        nx.draw_networkx_nodes(uG, pos, highlight_valves, node_size=200, node_shape='d', node_color='limegreen', edgecolors='white')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8ab6a264",
      "metadata": {
        "id": "8ab6a264"
      },
      "outputs": [],
      "source": [
        "#### DO NOT CHANGE THIS ####\n",
        "# hydraulic solver function\n",
        "def hydraulic_solver(inp_file, d_data, h0_data, C=None, demand=False):\n",
        "\n",
        "    # load network from wntr\n",
        "    inp_file = os.path.join(net_dir, net_name)\n",
        "    wn = wntr.network.WaterNetworkModel(inp_file)\n",
        "\n",
        "    # get network properties\n",
        "    reservoir_names = wn.reservoir_name_list\n",
        "    junction_names = wn.junction_name_list\n",
        "    link_names = wn.link_name_list\n",
        "\n",
        "    # modify simulation time and hydraulic time step\n",
        "    nt = h0_data.shape[1]\n",
        "    wn.options.time.duration = (nt - 1) * 3600\n",
        "    wn.options.time.hydraulic_timestep = 3600\n",
        "    wn.options.time.pattern_timestep = 3600\n",
        "    wn.options.time.report_timestep = 3600\n",
        "\n",
        "    # assign reservoir data\n",
        "    for (i, name) in enumerate(reservoir_names):\n",
        "        wn.add_pattern(f'h0_{i}', h0_data[i])\n",
        "        reservoir = wn.get_node(name)\n",
        "        reservoir.head_timeseries.base_value = 1\n",
        "        reservoir.head_timeseries.pattern_name = wn.get_pattern(f'h0_{i}')\n",
        "\n",
        "    # replace demand data\n",
        "    for idx, name in enumerate(junction_names):\n",
        "\n",
        "        if any(val != 0 for val in d_data[idx, :]):\n",
        "            node = wn.get_node(name)\n",
        "            d_pat = d_data[idx, :]\n",
        "            wn.add_pattern('d_'+name, d_pat)\n",
        "\n",
        "            for (i, num) in enumerate(node.demand_timeseries_list):\n",
        "                if i == 0:\n",
        "                    node.demand_timeseries_list[i].base_value = 1\n",
        "                    node.demand_timeseries_list[i].pattern_name = 'd_'+name\n",
        "                else:\n",
        "                    node.demand_timeseries_list[i].base_value = None\n",
        "                    node.demand_timeseries_list[i].pattern_name = None\n",
        "\n",
        "    # assign roughness (or HW) coefficients\n",
        "    if C is not None:\n",
        "        for name, link in wn.links():\n",
        "\n",
        "            # check if the link is a pipe\n",
        "            if isinstance(link, wntr.network.Pipe):\n",
        "                link.roughness = C[link_names.index(name)]\n",
        "\n",
        "            # check if link is a valve\n",
        "            elif isinstance(link, wntr.network.Valve):\n",
        "                link.minor_loss = C[link_names.index(name)]\n",
        "                link.initial_setting = C[link_names.index(name)]\n",
        "\n",
        "    # run simulation and get results\n",
        "    sim = wntr.sim.EpanetSimulator(wn)\n",
        "    results = sim.run_sim()\n",
        "\n",
        "    q_sim = results.link['flowrate'].T\n",
        "    h_sim = results.node['head'].T\n",
        "    h_sim = h_sim[~h_sim.index.isin(reservoir_names)] # delete reservoir nodes\n",
        "    d = results.node['demand'].T\n",
        "    d = d[~d.index.isin(reservoir_names)] # delete reservoir nodes\n",
        "\n",
        "\n",
        "    if demand == True:\n",
        "        return d.to_numpy()\n",
        "    else:\n",
        "        return q_sim.to_numpy(), h_sim.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55a5fa4e",
      "metadata": {},
      "source": [
        "Plot network and sensor locations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a5625f",
      "metadata": {
        "id": "a5a5625f"
      },
      "outputs": [],
      "source": [
        "plot_network(wdn, sensor_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e4e135d",
      "metadata": {
        "id": "8e4e135d"
      },
      "source": [
        "### Part 1 summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf326963",
      "metadata": {
        "id": "cf326963"
      },
      "source": [
        "In Part 1, we observed a very large spread in \"calibrated\" H-W coefficients $C_1$; since the parameter estimation problem is underdetermined (the number of H-W coefficients is much larger than the number of independent pressure measurements), many different solutions with similar objective values exist.\n",
        "\n",
        "In order to reduce the underdeterminedness of the model calibration problem (and improve the quality of estimated H-W coefficients), pipes can be grouped based on their material and age. In particular, all pipes of a group are assumed to share the same H-W coefficient. This also allows for **tighter bounds on the grouped coefficient estimates** $\\Theta$ (stored in `wdn.Theta_min` and `wdn.Theta_max`, for lower and upper bounds, respectively) in the formulation of the parameter estimation problem."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "769b2354",
      "metadata": {},
      "source": [
        "Split the data into *train* and *test* datasets. (We suggest using the first day worth of data as a <u>train dataset</u> and the remaining 3 days as a <u>test dataset</u>.) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2233eca0",
      "metadata": {
        "id": "2233eca0"
      },
      "outputs": [],
      "source": [
        "# tain data\n",
        "nt_train = 24\n",
        "data_train = {\n",
        "    'd': d_data[:, :nt_train],\n",
        "    'h0': h0_data[:, :nt_train],\n",
        "    'h_data': h_data[:, :nt_train]\n",
        "}\n",
        "\n",
        "# test data\n",
        "data_test = {\n",
        "    'd': d_data[:, nt_train:],\n",
        "    'h0': h0_data[:, nt_train:],\n",
        "    'h_data': h_data[:, nt_train:]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ccd2677",
      "metadata": {
        "id": "3ccd2677"
      },
      "source": [
        "Definition of the loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "396feded",
      "metadata": {
        "id": "396feded"
      },
      "outputs": [],
      "source": [
        "def loss_fun(h, h_data):\n",
        "    return ( 1/len(h_data.flatten()) ) * np.sum( ( h[sensor_idx, :] - h_data )**2 )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae82ecc6",
      "metadata": {
        "id": "ae82ecc6"
      },
      "source": [
        "The following function is needed for the sequential convex programming (SCP) method used in this coursework. As with the `hydraulic_solver` function, we provide the following code in `linear_approx_calibration` for you to use throughout this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67ac4ce4",
      "metadata": {
        "id": "67ac4ce4"
      },
      "outputs": [],
      "source": [
        "#### DO NOT CHANGE THIS ####\n",
        "# compute matrices for the head loss linear approximation of the HW headloss\n",
        "def linear_approx_calibration(wdn, q, C):\n",
        "    # unload data\n",
        "    A12 = wdn.A12\n",
        "    A10 = wdn.A10\n",
        "    net_info = wdn.net_info\n",
        "    link_df = wdn.link_df\n",
        "\n",
        "    K = np.zeros((net_info['np'], 1))\n",
        "    n_exp = link_df['n_exp'].astype(float).to_numpy().reshape(-1, 1)\n",
        "    b1_k = copy.copy(K)\n",
        "    b2_k = copy.copy(K)\n",
        "\n",
        "    for idx, row in link_df.iterrows():\n",
        "        if row['link_type'] == 'pipe':\n",
        "            K[idx] = 10.67 * row['length'] * (C[idx] ** -row['n_exp']) * (row['diameter'] ** -4.8704)\n",
        "            b1_k[idx] = copy.copy(K[idx])\n",
        "            b2_k[idx] = (-n_exp[idx] * K[idx]) / C[idx]\n",
        "\n",
        "        elif row['link_type'] == 'valve':\n",
        "            K[idx] = (8 / (np.pi ** 2 * 9.81)) * (row['diameter'] ** -4) * C[idx]\n",
        "            b1_k[idx] = -n_exp[idx] * copy.copy(K[idx])\n",
        "            b2_k[idx] = copy.copy(K[idx]) / C[idx]\n",
        "\n",
        "    a11_k = np.tile(K, q.shape[1]) * np.abs(q) ** (n_exp - 1)\n",
        "    b1_k = np.tile(b1_k, q.shape[1]) * np.abs(q) ** (n_exp - 1)\n",
        "    b2_k = np.tile(b2_k, q.shape[1]) * np.abs(q) ** (n_exp - 1) * q\n",
        "\n",
        "    return a11_k, b1_k, b2_k"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7cbaf70",
      "metadata": {
        "id": "b7cbaf70"
      },
      "source": [
        "### Part 2.1 Calibration of pipe H-W coefficients (<u>with</u> pipe grouping)\n",
        "In Part 2.1, you will still assume the status of valves in `wdn.valves` is known and **local loss coefficients are fixed to C=0.2**. Use the code provided in Week 4 and modify as necessary below to calibrate the hydraulic model **<u>with</u> pipe grouping**, using the same *train* dataset defined previously. (Note that this problem may take longer to run as it is more constrained than the problem solved in part 1.2.)    \n",
        "\n",
        "Solve the parameter estimation problem using the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef1e7d3d",
      "metadata": {
        "id": "ef1e7d3d"
      },
      "outputs": [],
      "source": [
        "# unload network training data\n",
        "n_exp = link_df['n_exp']\n",
        "d = data_train['d']\n",
        "h_data = data_train['h_data']\n",
        "h0 = data_train['h0'].reshape(-1, 1).T\n",
        "\n",
        "# define SCP problem parameters\n",
        "Ki = np.inf\n",
        "iter_max = 50\n",
        "delta_k = 20\n",
        "C_up_pipe = 200\n",
        "C_lo_pipe = 1e-4\n",
        "\n",
        "# initialise values\n",
        "theta_k = ...\n",
        "q_k, h_k = hydraulic_solver(...)\n",
        "a11_k, b1_k, b2_k = linear_approx_calibration(...)\n",
        "objval_k = loss_fun(...)\n",
        "\n",
        "### main scp code ###\n",
        "for k in range(iter_max):\n",
        "\n",
        "    # insert code here...."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5384145e",
      "metadata": {},
      "source": [
        "Store the solution (i.e. new coefficients `theta_k`) as $C_2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa280e4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "C_2 = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63bdf07a",
      "metadata": {},
      "source": [
        "Evaluate final model error and visualise head residuals corresponding to *test* dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7526d511",
      "metadata": {},
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ba17cc5",
      "metadata": {
        "id": "9ba17cc5"
      },
      "source": [
        "**<u>Question 2.1:</u>** Comment on the improvement in model accuracy after calibration <u>with</u> pipe grouping."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b062648a",
      "metadata": {
        "id": "b062648a"
      },
      "source": [
        "<font color=\"red\">Enter response here..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "113a7a36",
      "metadata": {
        "id": "113a7a36"
      },
      "source": [
        "**<u>Question 2.2:</u>** Comment on the values of the H-W coefficients $C_2$ and justify the calibration results **<u>with</u> pipe grouping**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b08167ab",
      "metadata": {
        "id": "b08167ab"
      },
      "source": [
        "<font color=\"red\">Enter response here..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae67620d",
      "metadata": {
        "id": "ae67620d"
      },
      "source": [
        "**<u>Question 2.3:</u>** Can the newly calibrated model be considered calibrated? Considering your results in Parts 1.2 and 2.1, provide an interpretation of the remaining pressure/head residuals."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b239bbea",
      "metadata": {},
      "source": [
        "<font color=\"red\">Enter response here..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc32064a",
      "metadata": {},
      "source": [
        "### Part 2.2\n",
        "Following initial reports concerning discrepancies in the EXNING model, AW were able to confirm that:\n",
        "* flow and head sensors had been calibrated before collection of load/field data corresponding to the *train* and *test* datasets,\n",
        "* allocation of demands in the *train* an *test* dataset in representative of normal network conditions and based on recent demand monitoring campaigns (including large industrial users),\n",
        "* boundary valves (isolating EXNING from adjacent DMAs) are closed.\n",
        "\n",
        "As a result, the remaining deviations between measured and simulated pressures must result from unknown/unreported model parameters.\n",
        "\n",
        "**In part 2.2**, you are encouraged to propose and investigate a new approach to solving the hydraulic model calibration problem. You may follow the suggested steps below, or come up with your own. Marks will be allocated based on the justification of the adopted approach (show your thinking!) and discussion of results in question 2.4, regardless of whether they lead to a definitive conclusion. Feel free to share and discuss your approach with classmates and/or reach out to us if you have any questions. However, please ensure that you answer all  questions.\n",
        "\n",
        "Suggested approach:\n",
        "1. Try modifying the CVXPY implementation of the hydraulic model calibration problem **<u>with</u> pipe grouping** (modify the code from part 2.1) to allow other model parameters to vary.\n",
        "2. Next, try further modifying the your CVXPY implementation to account for the expected sparsity pattern of additional model parameters.\n",
        "3. Finally, compare the results of part 2.2 with the results of part 1. Explain whether they contradict or corroborate your previous conclusions about the most likely sources of error in the EXNING model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfff1c7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "475125c0",
      "metadata": {},
      "source": [
        "**<u>Question 2.4:</u>** Summarise your findings and provide recommendations to AW to validate your proposed hydraulic model update."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc030717",
      "metadata": {},
      "source": [
        "<font color=\"red\">Enter response here..."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
