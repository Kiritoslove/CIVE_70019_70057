{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kiritoslove/CIVE_70019_70057/blob/main/notebooks/coursework_2025_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3ea0ffc",
      "metadata": {
        "id": "c3ea0ffc"
      },
      "source": [
        "# Coursework: Hydraulic model calibration\n",
        "\n",
        "\n",
        "### CIVE 70019/70057\n",
        "Department of Civil and Environmental Engineering, Imperial College London"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eebea76",
      "metadata": {
        "id": "5eebea76"
      },
      "source": [
        "You have been tasked with the evaluation and calibration of the hydraulic model of EXNING, a district metered area (DMA) in Anglian Water's (AW) water distribution network. To achieve this, you have been provided:\n",
        "* a recently calibrated hydraulic model of the EXNING DMA (2019),\n",
        "* loading conditions (demands, reservoir heads) and head measurements covering a period of 4 days.\n",
        "\n",
        "The objective of the coursework is to prepare a short calibration report for AW by completing the tasks below and answering the questions based on your results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ecf250d",
      "metadata": {
        "id": "1ecf250d"
      },
      "source": [
        "You have been provided the following information about EXNING:\n",
        "* EXNING is part of a larger system of cascading DMAs: EXNING is fed by the NEWSEV DMA and feeds into the BURWEL DMA.\n",
        "* The \"reservoir\" head and total demand of EXNING are derived from flow and pressure sensors at the DMA inlet (& outlet).\n",
        "* Node elevations have been updated in the provided model following a GPS survey of sensor locations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7aeb130",
      "metadata": {
        "id": "e7aeb130"
      },
      "source": [
        "First, we must clone the GitHub repository and install dependencies (only run this once)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "XUkd0ndZ-Fy_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUkd0ndZ-Fy_",
        "outputId": "0ee3f9c3-6ccb-44aa-852f-74377a094c93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CIVE_70019_70057' already exists and is not an empty directory.\n",
            "Requirement already satisfied: wntr==1.2 in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Collecting numpy<2.0,>=1.21 (from wntr==1.2)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from wntr==1.2) (1.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from wntr==1.2) (3.4.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from wntr==1.2) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from wntr==1.2) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wntr==1.2) (75.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wntr==1.2) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wntr==1.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wntr==1.2) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wntr==1.2) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wntr==1.2) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wntr==1.2) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wntr==1.2) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wntr==1.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->wntr==1.2) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->wntr==1.2) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->wntr==1.2) (1.17.0)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.4\n",
            "    Uninstalling numpy-2.2.4:\n",
            "      Successfully uninstalled numpy-2.2.4\n",
            "Successfully installed numpy-1.26.4\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.11/dist-packages (1.6.3)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from cvxpy) (0.6.7.post3)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy) (0.10.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/dist-packages (from cvxpy) (3.2.7.post2)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from cvxpy) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy) (1.14.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy) (0.1.7.post5)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libsuitesparse-dev is already the newest version (1:5.10.1+dfsg-4build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Requirement already satisfied: scikit-sparse in /usr/local/lib/python3.11/dist-packages (0.4.15)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from scikit-sparse) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.11/dist-packages (from scikit-sparse) (1.14.1)\n"
          ]
        }
      ],
      "source": [
        "# run this cell once\n",
        "import sys\n",
        "import os\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  !git clone https://github.com/bradleywjenks/CIVE_70019_70057.git\n",
        "  !pip install wntr==1.2\n",
        "  !pip install cvxpy\n",
        "  !apt-get install libsuitesparse-dev && pip install scikit-sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "Bg3A6sO13PRH",
      "metadata": {
        "id": "Bg3A6sO13PRH",
        "outputId": "aa553508-6b66-4cb6-d5a3-1f85b21a0fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy.char'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0c2b3d017a72>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwntr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wntr/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwntr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mepanet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwntr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwntr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmorph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwntr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwntr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wntr/epanet/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mwntr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepanet\u001b[0m \u001b[0mpackage\u001b[0m \u001b[0mprovides\u001b[0m \u001b[0mEPANET2\u001b[0m \u001b[0mcompatibility\u001b[0m \u001b[0mfunctions\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mWNTR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInpFile\u001b[0m  \u001b[0;31m#, BinFile, HydFile, RptFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlowUnits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMassUnits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHydParam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQualParam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtoolkit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wntr/epanet/io.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwntr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwntr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepanet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mENKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mENSyntaxError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mENValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEpanetException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwntr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwntr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m from wntr.network.controls import (AndCondition, Comparison, Control,\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wntr/network/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNodeType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinkType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinkStatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0melements\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReservoir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPump\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPattern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mTimeSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDemands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCurve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWaterNetworkModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wntr/network/elements.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcurve_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptimizeWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMutableSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    412\u001b[0m \"\"\"  # noqa: E501\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_optimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_minimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m                    asarray, sqrt)\n\u001b[1;32m     34\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcholesky\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0missymmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearOperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m from ._linesearch import (line_search_wolfe1, line_search_wolfe2,\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/linalg/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_misc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_cythonized_array_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_basic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_decomp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_decomp_lu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/linalg/_basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlapack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_lapack_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_compute_lwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_misc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_datacopied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinAlgWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_decomp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_decomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_decomp_svd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_solve_toeplitz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlevinson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/linalg/_decomp.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                    iscomplex, zeros, einsum, eye, inf)\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Local imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_misc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_datacopied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlapack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_lapack_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_compute_lwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_namespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxp_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/_array_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_api_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m from scipy._lib.array_api_compat import (\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mis_array_api_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/array_api_compat/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# from numpy import * doesn't overwrite these builtin names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             msg = (\"The current Numpy installation ({!r}) fails to \"\n\u001b[0m\u001b[1;32m    368\u001b[0m                    \u001b[0;34m\"pass simple sanity checks. This can be caused for example \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                    \u001b[0;34m\"by incorrect BLAS library being linked in, or by mixing \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.char'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# load packages\n",
        "import numpy as np\n",
        "from numpy import linalg as la\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import wntr\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import copy\n",
        "from datetime import datetime, timedelta\n",
        "import cvxpy as cp\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# improve matplotlib image quality\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "import matplotlib_inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Im1H-3E-2rNx",
      "metadata": {
        "id": "Im1H-3E-2rNx"
      },
      "source": [
        "### Load network properties and operational data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18ff4e16",
      "metadata": {
        "id": "18ff4e16"
      },
      "source": [
        "Load functions created in previous assignments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b8e8f67",
      "metadata": {
        "id": "3b8e8f67"
      },
      "outputs": [],
      "source": [
        "# load functions from src folder\n",
        "if 'google.colab' in sys.modules:\n",
        "    sys.path.append('/content/CIVE_70019_70057/src/')\n",
        "    from general_functions import *\n",
        "    from hydraulic_functions import *\n",
        "else:\n",
        "    sys.path.append('/home/bradw/workspace/CIVE_70019_70057/src/')\n",
        "    from general_functions import *\n",
        "    from hydraulic_functions import *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8S6RiXY_28PC",
      "metadata": {
        "id": "8S6RiXY_28PC"
      },
      "source": [
        "Load network .inp file and operational data from the module repository's data directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x9vbD66O22q_",
      "metadata": {
        "id": "x9vbD66O22q_"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "    # if run in Google Colab\n",
        "    data_dir = '/content/CIVE_70019_70057/data/parameter_estimation/'\n",
        "    net_dir = '/content/CIVE_70019_70057/data/networks/'\n",
        "else:\n",
        "    # replace with local directory\n",
        "    data_dir = '/home/bradw/workspace/CIVE_70019_70057/data/parameter_estimation/'\n",
        "    net_dir = '/home/bradw/workspace/CIVE_70019_70057/data/networks/'\n",
        "\n",
        "net_name = 'exning.inp'\n",
        "data_name = 'exning_coursework_dataset.npy'\n",
        "\n",
        "# load operational data\n",
        "data = np.load(os.path.join(data_dir, data_name), allow_pickle=True).item()\n",
        "h_data = data['h_data']\n",
        "sensor_idx = data['sensor_idx'] - 1 # matlab to python index offset\n",
        "d_data = data['d']\n",
        "h0_data = data['h0'].reshape(-1, 1).T\n",
        "\n",
        "# load network properties\n",
        "wdn = load_network_data(os.path.join(net_dir, net_name))\n",
        "A12 = wdn.A12\n",
        "A10 = wdn.A10\n",
        "A21 = A12.T\n",
        "net_info = wdn.net_info\n",
        "link_df = wdn.link_df\n",
        "node_df = wdn.node_df\n",
        "demand_df = wdn.demand_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(d_data.shape)"
      ],
      "metadata": {
        "id": "fT5V9FpIcDA_"
      },
      "id": "fT5V9FpIcDA_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "IVw1luezmfxv",
      "metadata": {
        "id": "IVw1luezmfxv"
      },
      "source": [
        "Plot sensor nodes in network. We provide a plotting function below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec181359",
      "metadata": {
        "id": "ec181359"
      },
      "outputs": [],
      "source": [
        "#### DO NOT CHANGE THIS ####\n",
        "# define plotting function using networkx\n",
        "def plot_network(wdn, sensor_idx, vals=None, highlight_valves=None):\n",
        "\n",
        "    # create figure and axis\n",
        "    fig, ax = plt.subplots(figsize=(10, 7))\n",
        "\n",
        "    # unload data\n",
        "    link_df = wdn.link_df\n",
        "    node_df = wdn.node_df\n",
        "    net_info = wdn.net_info\n",
        "\n",
        "    # draw network\n",
        "    uG = nx.from_pandas_edgelist(link_df, source='node_out', target='node_in')\n",
        "    pos = {row['node_ID']: (row['xcoord'], row['ycoord']) for _, row in node_df.iterrows()}\n",
        "    nx.draw(uG, pos, ax=ax, node_size=20, node_shape='o')\n",
        "\n",
        "    # draw reservoir\n",
        "    nx.draw_networkx_nodes(\n",
        "        uG, pos, nodelist=net_info['reservoir_names'],\n",
        "        node_size=100, node_shape='s', node_color='black', ax=ax\n",
        "    )\n",
        "\n",
        "    # draw sensor nodes\n",
        "    sensor_names = [net_info['junction_names'][i] for i in sensor_idx]\n",
        "    nx.draw_networkx_nodes(\n",
        "        uG, pos, nodelist=sensor_names, node_size=100,\n",
        "        node_shape='o', node_color='red', edgecolors='white', ax=ax\n",
        "    )\n",
        "\n",
        "    # reservoir labels\n",
        "    reservoir_labels = {node: 'Reservoir' for node in net_info['reservoir_names']}\n",
        "    labels_res = nx.draw_networkx_labels(uG, pos, reservoir_labels, font_size=12, ax=ax)\n",
        "    for _, label in labels_res.items():\n",
        "        label.set_y(label.get_position()[1] + 1750)\n",
        "\n",
        "    # sensor labels\n",
        "    sensor_labels = {node: str(idx+1) for (idx, node) in enumerate(sensor_names)}\n",
        "    labels_sen = nx.draw_networkx_labels(uG, pos, sensor_labels, font_size=12, ax=ax)\n",
        "    for _, label in labels_sen.items():\n",
        "        label.set_y(label.get_position()[1] + 1750)\n",
        "\n",
        "    # plot sensor values if provided\n",
        "    if vals is not None:\n",
        "        cmap = cm.get_cmap('RdYlGn_r')\n",
        "        nx.draw_networkx_nodes(\n",
        "            uG, pos, nodelist=sensor_names, node_size=100,\n",
        "            node_shape='o', node_color=vals, cmap=cmap, edgecolors='white', ax=ax\n",
        "        )\n",
        "\n",
        "        # create color bar\n",
        "        sm = plt.cm.ScalarMappable(cmap=cmap)\n",
        "        sm.set_array(vals)\n",
        "        colorbar = plt.colorbar(sm, ax=ax)\n",
        "        colorbar.set_label('Mean pressure residual [m]', fontsize=12)\n",
        "\n",
        "    # highlight link\n",
        "    if highlight_valves is not None:\n",
        "        nx.draw_networkx_nodes(uG, pos, highlight_valves, node_size=200, node_shape='d', node_color='limegreen', edgecolors='white')\n",
        "\n",
        "    # display plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5c6d579",
      "metadata": {
        "id": "e5c6d579"
      },
      "source": [
        "Visualise the EXNING network graph and highlight information relevant to the evaluation of the hydraulic model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a5625f",
      "metadata": {
        "id": "a5a5625f"
      },
      "outputs": [],
      "source": [
        "plot_network(wdn, sensor_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf326963",
      "metadata": {
        "id": "cf326963"
      },
      "source": [
        "Simulate initial (uncalibrated) network hydraulics over 4 days. We first define a function to solve network hydraulics using the `wntr` package, which we used previously in the hyraulic modelling notebook. The following tasks are performed in this function:\n",
        "- Load network properties\n",
        "- Modify simulation time to match operational data\n",
        "- Assign h0 data at model reservoir\n",
        "- Scale and apply new demand pattern from inflow data\n",
        "- Option to modify pipe roughness (or HW) coefficients\n",
        "\n",
        "<font color=\"blue\">NB: this is done for you below. Provided the correct inputs, you do not need to replicate this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ab6a264",
      "metadata": {
        "id": "8ab6a264"
      },
      "outputs": [],
      "source": [
        "#### DO NOT CHANGE THIS ####\n",
        "# hydraulic solver function\n",
        "def hydraulic_solver(inp_file, d_data, h0_data, C=None, demand=False):\n",
        "\n",
        "    # load network from wntr\n",
        "    inp_file = os.path.join(net_dir, net_name)\n",
        "    wn = wntr.network.WaterNetworkModel(inp_file)\n",
        "\n",
        "    # get network properties\n",
        "    reservoir_names = wn.reservoir_name_list\n",
        "    junction_names = wn.junction_name_list\n",
        "    link_names = wn.link_name_list\n",
        "\n",
        "    # modify simulation time and hydraulic time step\n",
        "    nt = h0_data.shape[1]\n",
        "    wn.options.time.duration = (nt - 1) * 3600\n",
        "    wn.options.time.hydraulic_timestep = 3600\n",
        "    wn.options.time.pattern_timestep = 3600\n",
        "    wn.options.time.report_timestep = 3600\n",
        "\n",
        "    # assign reservoir data\n",
        "    for (i, name) in enumerate(reservoir_names):\n",
        "        wn.add_pattern(f'h0_{i}', h0_data[i])\n",
        "        reservoir = wn.get_node(name)\n",
        "        reservoir.head_timeseries.base_value = 1\n",
        "        reservoir.head_timeseries.pattern_name = wn.get_pattern(f'h0_{i}')\n",
        "\n",
        "    # replace demand data\n",
        "    for idx, name in enumerate(junction_names):\n",
        "\n",
        "        if any(val != 0 for val in d_data[idx, :]):\n",
        "            node = wn.get_node(name)\n",
        "            d_pat = d_data[idx, :]\n",
        "            wn.add_pattern('d_'+name, d_pat)\n",
        "\n",
        "            for (i, num) in enumerate(node.demand_timeseries_list):\n",
        "                if i == 0:\n",
        "                    node.demand_timeseries_list[i].base_value = 1\n",
        "                    node.demand_timeseries_list[i].pattern_name = 'd_'+name\n",
        "                else:\n",
        "                    node.demand_timeseries_list[i].base_value = None\n",
        "                    node.demand_timeseries_list[i].pattern_name = None\n",
        "\n",
        "    # assign roughness (or HW) coefficients\n",
        "    if C is not None:\n",
        "        for name, link in wn.links():\n",
        "\n",
        "            # check if the link is a pipe\n",
        "            if isinstance(link, wntr.network.Pipe):\n",
        "                link.roughness = C[link_names.index(name)]\n",
        "\n",
        "            # check if link is a valve\n",
        "            elif isinstance(link, wntr.network.Valve):\n",
        "                link.minor_loss = C[link_names.index(name)]\n",
        "                link.initial_setting = C[link_names.index(name)]\n",
        "\n",
        "    # run simulation and get results\n",
        "    sim = wntr.sim.EpanetSimulator(wn)\n",
        "    results = sim.run_sim()\n",
        "\n",
        "    q_sim = results.link['flowrate'].T\n",
        "    h_sim = results.node['head'].T\n",
        "    h_sim = h_sim[~h_sim.index.isin(reservoir_names)] # delete reservoir nodes\n",
        "    d = results.node['demand'].T\n",
        "    d = d[~d.index.isin(reservoir_names)] # delete reservoir nodes\n",
        "\n",
        "\n",
        "    if demand == True:\n",
        "        return d.to_numpy()\n",
        "    else:\n",
        "        return q_sim.to_numpy(), h_sim.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bf50026",
      "metadata": {
        "id": "0bf50026"
      },
      "source": [
        "### Part 0: Preliminary evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ccd2677",
      "metadata": {
        "id": "3ccd2677"
      },
      "source": [
        "Run simulation with initial $C_0$ values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "396feded",
      "metadata": {
        "id": "396feded"
      },
      "outputs": [],
      "source": [
        "C_0 = link_df['C'].to_numpy()\n",
        "_, h_0 = hydraulic_solver(wdn, d_data, h0_data,C=C_0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1529c117",
      "metadata": {
        "id": "1529c117"
      },
      "source": [
        "Compare simulated heads at sensor nodes (node indices in `sensor_idx`) with the simulated heads over the 4-day period. Visualise the results with, e.g. a boxplot of pressure residuals on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8324840",
      "metadata": {
        "id": "f8324840"
      },
      "outputs": [],
      "source": [
        "h_meas = h_data  # true observation data\n",
        "h_sim = h_0[sensor_idx,:]  # h by simulation\n",
        "\n",
        "\n",
        "h_residuals = h_meas - h_sim\n",
        "h_residuals_square = np.square(h_meas - h_sim)\n",
        "\n",
        "print(\"Residuals shape:\", h_residuals.shape)\n",
        "mse = np.mean((h_0[sensor_idx,: ] - data['h_data']) ** 2)\n",
        "print(f\"\\n总均方误差 (MSE): {mse:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute pressure residuals\n",
        "residuals_0 = h_0[sensor_idx,:] - h_data\n",
        "\n",
        "# create figure and axis for box plots\n",
        "fig, ax = plt.subplots()\n",
        "boxplot = ax.boxplot(residuals_0.T, medianprops=dict(color=\"red\", linewidth=1.0), flierprops=dict(marker=\"+\", markeredgecolor=\"red\"), whiskerprops=dict(linestyle=(5, (8, 5)), linewidth=0.6), boxprops=dict(color='black', linewidth=0.6), capprops=dict(linewidth=0.6))\n",
        "ax.set_xlabel('Sensor index', fontsize=12)\n",
        "ax.set_ylabel('Pressure residual [m]', fontsize=12)"
      ],
      "metadata": {
        "id": "Tg6BpblVrkNf"
      },
      "id": "Tg6BpblVrkNf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spatial residuals plot\n",
        "mean_residuals_0 = np.mean(residuals_0, axis=1)\n",
        "plot_network(wdn, sensor_idx, vals=mean_residuals_0)"
      ],
      "metadata": {
        "id": "r_wNY6POwE8Q"
      },
      "id": "r_wNY6POwE8Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C_0 value scatter plot (valves only)\n",
        "valve_C = [C_0[idx] for idx, row in link_df.iterrows() if row['link_type'] == 'valve']\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(range(len(valve_C)), valve_C, facecolors='none', edgecolors='b',linewidths=0.75)\n",
        "ax.set_xlabel('Valve index', fontsize=12)\n",
        "ax.set_ylabel('Initial C_0 value', fontsize=12)\n",
        "for axis in ['top','bottom','left','right']:\n",
        "    ax.spines[axis].set_linewidth(0.5)"
      ],
      "metadata": {
        "id": "7JXeYVWEqx-_"
      },
      "id": "7JXeYVWEqx-_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_residuals = np.mean(h_residuals, axis=1)\n",
        "plot_network(wdn, sensor_idx, vals=mean_residuals)"
      ],
      "metadata": {
        "id": "kJwZLtfrH7iw"
      },
      "id": "kJwZLtfrH7iw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#print(h_residuals)\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# seaborn boxplot\n",
        "sns.boxplot(data=h_residuals.T)\n",
        "plt.xticks(ticks=range(14), labels=range(1, 15))\n",
        "plt.title(\"Boxplot of Residuals per sensor\")\n",
        "plt.xlabel(\"sensor_index\")\n",
        "plt.ylabel(\"Residuals\")"
      ],
      "metadata": {
        "id": "sNDwxw4iKrfF"
      },
      "id": "sNDwxw4iKrfF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "time_points = np.arange(h_0.shape[1])  # Create a time index\n",
        "\n",
        "sensor_labels = {sensor: str(idx+1) for idx, sensor in enumerate(sensor_idx)}\n",
        "\n",
        "for i, sensor in enumerate(sensor_idx):\n",
        "    plt.plot(time_points, h_residuals[i], label=f\"Sensor {sensor_labels[sensor]}\")\n",
        "\n",
        "plt.axhline(0, color='black', linestyle='--', alpha=0.7)\n",
        "plt.xlabel(\"Time (hours)\")\n",
        "plt.ylabel(\"Pressure Residuals (m)\")\n",
        "plt.title(\"Pressure Residuals Over Time\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lcZLrI3cILzT"
      },
      "id": "lcZLrI3cILzT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Creating interactive charts\n",
        "fig = go.Figure()\n",
        "\n",
        "# reflex\n",
        "sensor_labels = {sensor: f\"Sensor {idx+1}\" for idx, sensor in enumerate(sensor_idx)}\n",
        "\n",
        "for i, sensor in enumerate(sensor_idx):\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=np.arange(h_0.shape[1]),\n",
        "        y=h_residuals[i],\n",
        "        mode='lines',\n",
        "        name=sensor_labels[sensor],  # legend lable\n",
        "        hoverinfo='x+y'  # Hovering the mouse will display the time and error value\n",
        "    ))\n",
        "\n",
        "# Setting the chart title and axis labels\n",
        "fig.update_layout(\n",
        "    title=\"Pressure Residuals Over Time\",\n",
        "    xaxis_title=\"Time (hours)\",\n",
        "    yaxis_title=\"Pressure Residuals (m)\",\n",
        "    legend_title=\"Sensor Number\",\n",
        "    template=\"plotly_white\"\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "7s7FVw2mLQQg"
      },
      "id": "7s7FVw2mLQQg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b8380051",
      "metadata": {
        "id": "b8380051"
      },
      "source": [
        "**<u>Question 1:</u>** Is the current hydraulic model of EXNING accurate according to hydraulic model calibration guidelines? Comment on the results of the preliminary model evaluation and, in particular, on\n",
        "* the **sign** (i.e. are heads over or underestimated in the hydraulic simulation?) of pressure/head residuals,\n",
        "* the **temporal** distribution (i.e. are the residuals time/flow dependent?) of pressure/head residuals,\n",
        "* and the **spatial** distribution (i.e. are all sensors affected?) of the pressure/head residuals.\n",
        "\n",
        "Given the information you were provided about the EXNING system and the results of the preliminary model evaluation, identify the most likely sources of model errors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28ee1f6b",
      "metadata": {
        "id": "28ee1f6b"
      },
      "source": [
        "<font color=\"red\">Enter response here..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76b6d8f8",
      "metadata": {
        "id": "76b6d8f8"
      },
      "source": [
        "### Part 1: Hydraulic model calibration (without regularisation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4133aa18",
      "metadata": {
        "id": "4133aa18"
      },
      "source": [
        "Following initial reports concerning discrepancies in the recently calibrated EXNING model, AW were able to confirm that:\n",
        "- flow and head sensors had been calibrated before collection of load/field data corresponding to the train and test datasets,\n",
        "- demands in the train and test dataset are accurate (incl. for large users).\n",
        "\n",
        "As a result, the remaining deviations between measured and simulated pressures must result from inaccurate model parameters. Errors associated with unknown valve status (for instance, unregistered closed valves) can be identified by solving a model calibration problem where pipe roughness coefficients are known, but valve minor/local loss coefficients are free to vary. In part 1, you will solve a hydraulic model calibration problem without regularisation. Complete the code below to calibrate the network model using the head measurements provided in data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7fa0ee6",
      "metadata": {
        "id": "a7fa0ee6"
      },
      "source": [
        "#### Split the data into *train* and *test* datasets.\n",
        "We suggest using the first day worth of data as a <u>train dataset</u> and the remaining 3 days as a <u>test dataset</u>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1dfbaa9",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "a1dfbaa9"
      },
      "outputs": [],
      "source": [
        "# tain data\n",
        "nt_train = 24\n",
        "data_train = {\n",
        "    'd': d_data[:, :nt_train],\n",
        "    'h0': h0_data[:, :nt_train],\n",
        "    'h_data': h_data[:, :nt_train]\n",
        "}\n",
        "\n",
        "# test data\n",
        "data_test = {\n",
        "    'd': d_data[:, nt_train:],\n",
        "    'h0': h0_data[:, nt_train:],\n",
        "    'h_data': h_data[:, nt_train:]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01064549",
      "metadata": {
        "id": "01064549"
      },
      "source": [
        "**<u>Question 2:</u>** Briefly comment on the definition of the train data set. What impact will it have on the generalizability of your model? (i.e., what range of conditions will you confidently be able to use your model for?)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3500f75",
      "metadata": {
        "id": "e3500f75"
      },
      "source": [
        "#### Definition of the loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5aa2181",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "c5aa2181"
      },
      "outputs": [],
      "source": [
        "def loss_fun(h, h_data):\n",
        "    return ( 1/len(h_data.flatten()) ) * cp.sum( ( h[sensor_idx, :] - h_data )**2 )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute MSE for C_0 values and using thetraining data."
      ],
      "metadata": {
        "id": "IWS4WFdaPcSC"
      },
      "id": "IWS4WFdaPcSC"
    },
    {
      "cell_type": "code",
      "source": [
        "h_0 = h_0[:, :nt_train]\n",
        "mse_0 = loss_fun(h_0, data_train['h_data']).value\n",
        "mse_0"
      ],
      "metadata": {
        "id": "XZi42yEywh4Y"
      },
      "id": "XZi42yEywh4Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b77879b3",
      "metadata": {
        "id": "b77879b3"
      },
      "source": [
        "**<u>Question 3:</u>** Justify the choice/definition of the loss function, loss_fun."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31616869",
      "metadata": {
        "id": "31616869"
      },
      "source": [
        "#### Solve the parameter estimation problem using the train dataset\n",
        "We first solve the hydraulic model calibration problem without regularisation. (You can reuse and adapt the code provided in Week 6.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04fadcf0",
      "metadata": {
        "id": "04fadcf0"
      },
      "source": [
        "The following function is needed for the sequential convex programming (SCP) method used in this coursework. As with the `hydraulic_solver` function, we provide the following code in `linear_approx_calibration` for you to use throughout this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14ac1998",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "14ac1998"
      },
      "outputs": [],
      "source": [
        "#### DO NOT CHANGE THIS ####\n",
        "# compute matrices for the head loss linear approximation of the HW headloss\n",
        "def linear_approx_calibration(wdn, q, C):\n",
        "    # unload data\n",
        "    A12 = wdn.A12\n",
        "    A10 = wdn.A10\n",
        "    net_info = wdn.net_info\n",
        "    link_df = wdn.link_df\n",
        "\n",
        "    K = np.zeros((net_info['np'], 1))\n",
        "    n_exp = link_df['n_exp'].astype(float).to_numpy().reshape(-1, 1)\n",
        "    b1_k = copy.copy(K)\n",
        "    b2_k = copy.copy(K)\n",
        "\n",
        "    for idx, row in link_df.iterrows():\n",
        "        if row['link_type'] == 'pipe':\n",
        "            K[idx] = 10.67 * row['length'] * (C[idx] ** -row['n_exp']) * (row['diameter'] ** -4.8704)\n",
        "            b1_k[idx] = copy.copy(K[idx])\n",
        "            b2_k[idx] = (-n_exp[idx] * K[idx]) / C[idx]\n",
        "\n",
        "        elif row['link_type'] == 'valve':\n",
        "            K[idx] = (8 / (np.pi ** 2 * 9.81)) * (row['diameter'] ** -4) * C[idx]\n",
        "            b1_k[idx] = -n_exp[idx] * copy.copy(K[idx])\n",
        "            b2_k[idx] = copy.copy(K[idx]) / C[idx]\n",
        "\n",
        "    a11_k = np.tile(K, q.shape[1]) * np.abs(q) ** (n_exp - 1)\n",
        "    b1_k = np.tile(b1_k, q.shape[1]) * np.abs(q) ** (n_exp - 1)\n",
        "    b2_k = np.tile(b2_k, q.shape[1]) * np.abs(q) ** (n_exp - 1) * q\n",
        "\n",
        "    return a11_k, b1_k, b2_k"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unload network training data\n",
        "n_exp = link_df['n_exp']\n",
        "d = data_train['d']\n",
        "h_data = data_train['h_data']\n",
        "h0 = data_train['h0'].reshape(-1, 1).T\n",
        "\n",
        "# define problem parameters\n",
        "Ki = np.inf\n",
        "iter_max = 50\n",
        "delta_k = 167\n",
        "C_up_pipe = 200\n",
        "C_lo_pipe = 1e-4\n",
        "\n",
        "# initialise values\n",
        "theta_k = C_0\n",
        "q_k, h_k = hydraulic_solver(os.path.join(net_dir, net_name), d, h0, C=theta_k)\n",
        "a11_k, b1_k, b2_k = linear_approx_calibration(wdn, q_k, theta_k)\n",
        "objval_k = loss_fun(h_k, h_data).value\n",
        "\n",
        "### main scp code ###\n",
        "for k in range(iter_max):\n",
        "\n",
        "    # decision variables\n",
        "    q = cp.Variable((net_info['np'], nt_train))\n",
        "    h = cp.Variable((net_info['nn'], nt_train))\n",
        "    theta = cp.Variable(net_info['np'])\n",
        "\n",
        "    # objective function (defined using CVXPY functions)\n",
        "    loss = ( 1/len(h_data.flatten()) ) * cp.sum_squares( h[sensor_idx,:] - h_data )\n",
        "    objective = cp.Minimize(loss)\n",
        "\n",
        "    # hydraulic feasibility constraints\n",
        "    constraints = []\n",
        "    for t in range(nt_train):\n",
        "        # energy and mass constraints\n",
        "        constraints += [\n",
        "            cp.multiply(b1_k[:, t], q_k[:, t]) + cp.multiply(cp.multiply(n_exp, a11_k[:, t]), q[:, t]) + cp.multiply(b2_k[:, t], theta) + A12 @ h[:, t] + A10 @ h0[:, t] == 0,\n",
        "            A12.T @ q[:, t] == d[:, t]\n",
        "        ]\n",
        "\n",
        "    # trust region constraints\n",
        "    constraints += [\n",
        "        cp.norm(theta - theta_k, 'inf') <= delta_k\n",
        "    ]\n",
        "\n",
        "    # variable bounds\n",
        "    lower_bound_pipe = [theta[idx] >= C_lo_pipe for idx, row in link_df.iterrows() if row['link_type'] == 'valve']\n",
        "    constraints += lower_bound_pipe\n",
        "    upper_bound_pipe = [theta[idx] <= C_up_pipe for idx, row in link_df.iterrows() if row['link_type'] == 'valve']\n",
        "    constraints += upper_bound_pipe\n",
        "\n",
        "    # valve minor loss coefficient constraints\n",
        "    valve_constraints = [theta[idx] == C_0[idx] for idx, row in link_df.iterrows() if row['link_type'] == 'pipe']\n",
        "    constraints += valve_constraints\n",
        "\n",
        "    # solve optimisation problem\n",
        "    problem = cp.Problem(objective, constraints)\n",
        "    cvx_val = problem.solve(solver=cp.SCS, verbose=False, max_iters = 1000, eps=1e-3)\n",
        "\n",
        "    # store optimal solution and compute actual and predicted decrease in objval\n",
        "    theta_tilde = theta.value\n",
        "    [q_tilde, h_tilde] = hydraulic_solver(os.path.join(net_dir, net_name), d, h0, C=theta_tilde)\n",
        "    objval_tilde = loss_fun(h_tilde, h_data).value\n",
        "\n",
        "    predicted_decrease = objval_k - cvx_val\n",
        "    actual_decrease = objval_k - objval_tilde\n",
        "\n",
        "    # evaluate latest SCP iteration\n",
        "    if actual_decrease / predicted_decrease >= 0.1:\n",
        "        objval_old = objval_k\n",
        "        theta_k = theta_tilde\n",
        "        q_k = q_tilde\n",
        "        h_k = h_tilde\n",
        "        objval_k = objval_tilde\n",
        "        a11_k, b1_k, b2_k = linear_approx_calibration(wdn, q_k, theta_k)\n",
        "        Ki = np.abs(objval_old - objval_k) / np.abs(objval_old)\n",
        "        delta_k = 1.1 * delta_k\n",
        "        print(f\"Iteration {k} successful! Update estimate and increase trust region size. \\n\")\n",
        "\n",
        "    else:\n",
        "        delta_k = 0.25 * delta_k\n",
        "        print(f\"Iteration {k} unsuccessful! Return to previous estimate and reduce trust region size. \\n\")\n",
        "\n",
        "    print(f\"{k} {objval_k} {Ki} {delta_k} \\n\")\n",
        "\n",
        "    if Ki <= 1e-3 or np.abs(objval_k) <= 1e-2 or delta_k <= 1e-1:\n",
        "        break"
      ],
      "metadata": {
        "id": "PFdD79SnjcjS"
      },
      "id": "PFdD79SnjcjS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "delta167min"
      ],
      "metadata": {
        "id": "AYHNV34qBfAC"
      },
      "id": "AYHNV34qBfAC"
    },
    {
      "cell_type": "markdown",
      "id": "8144f58b",
      "metadata": {
        "id": "8144f58b"
      },
      "source": [
        "SCP implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01a05574",
      "metadata": {
        "id": "01a05574"
      },
      "source": [
        "**<u>Question 4:</u>** Describe the nature/role of the different outputs of the SCP algorithm printed above (objvalk, Ki, Deltak) and explain their trends."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95397f48",
      "metadata": {
        "id": "95397f48"
      },
      "source": [
        "Store the solution (i.e. new coefficients `theta_k`) as $C_1$."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_1 = theta_k\n",
        "print(C_1)\n",
        "q_k, h_k = hydraulic_solver(wdn, d, h0, C=C_1)\n",
        "mes_train = np.mean((h_k[sensor_idx, :] - h_data) ** 2)\n",
        "print(mes_train)\n",
        "\n",
        "q_test, h_test = hydraulic_solver(wdn, data_test['d'], data_test['h0'], C=C_1)\n",
        "mse_test = np.mean((h_test[sensor_idx,: ] - data_test['h_data']) ** 2)\n",
        "print(f\"\\n测试集均方误差 (MSE): {mse_test:.6f}\")"
      ],
      "metadata": {
        "id": "RXHrMZZ08eDL"
      },
      "id": "RXHrMZZ08eDL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "37506999",
      "metadata": {
        "id": "37506999"
      },
      "source": [
        "Evaluate final model error and visualise head residuals corresponding to *test* dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "h_residuals_1 =  h_test[sensor_idx,:] - data_test['h_data']\n",
        "\n",
        "print(\"Residuals shape:\", h_residuals_1.shape)"
      ],
      "metadata": {
        "id": "CbKNAs_Aiyqf"
      },
      "id": "CbKNAs_Aiyqf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_residuals_1 = np.mean(h_residuals_1, axis=1)\n",
        "plot_network(wdn, sensor_idx, vals=mean_residuals_1)"
      ],
      "metadata": {
        "id": "gjnCx4HNOY6g"
      },
      "id": "gjnCx4HNOY6g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "time_points = np.arange(data_test['h_data'].shape[1])  # Create a time index\n",
        "\n",
        "sensor_labels = {sensor: str(idx+1) for idx, sensor in enumerate(sensor_idx)}\n",
        "\n",
        "for i, sensor in enumerate(sensor_idx):\n",
        "    plt.plot(time_points, h_residuals_1[i], label=f\"Sensor {sensor_labels[sensor]}\")\n",
        "\n",
        "plt.axhline(0, color='black', linestyle='--', alpha=0.7)\n",
        "plt.xlabel(\"Time (hours)\")\n",
        "plt.ylabel(\"Pressure Residuals (m)\")\n",
        "plt.title(\"Pressure Residuals Over Time\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z0SX56Y6jFMR"
      },
      "id": "Z0SX56Y6jFMR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c12075e7",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "c12075e7"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d485f7b",
      "metadata": {
        "id": "3d485f7b"
      },
      "source": [
        "**<u>Question 5:</u>** Comment on the improvement in model accuracy (before vs. after calibration)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bfb232f",
      "metadata": {
        "id": "5bfb232f"
      },
      "source": [
        "#### Discuss the values of the calibrated coefficients $C_1$\n",
        "Visualise the values of newly calibrated coefficients $C_1$ compared to original model coefficients C."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ff13ebf",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "5ff13ebf"
      },
      "outputs": [],
      "source": [
        "# C_1 value scatter plot (valves only)\n",
        "valve_C1 = [C_1[idx] for idx, row in link_df.iterrows() if row['link_type'] == 'valve']\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(valve_C, valve_C1, facecolors='none', edgecolors='b',linewidths=0.75)\n",
        "ax.set_xlabel('C_0 value', fontsize=12)\n",
        "ax.set_ylabel('Calibrated C_1 value', fontsize=12)\n",
        "for axis in ['top','bottom','left','right']:\n",
        "    ax.spines[axis].set_linewidth(0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e446f19",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "0e446f19"
      },
      "source": [
        "**<u>Question 6:</u>** Comment on the values of parameter estimates in and explain the results of the calibration without regularisation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54ff6d0d",
      "metadata": {
        "id": "54ff6d0d"
      },
      "source": [
        "### Part 2: Hydraulic model calibration (with regularisation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32695bb0",
      "metadata": {
        "id": "32695bb0"
      },
      "source": [
        "In order to reduce the underdeterminedness of the hydraulic model calibration problem (and improve the accuracy of the calibrated model), regularisation can be applied to incorporate prior knowledge about the expected variance or sparsity pattern of parameters $\\theta$. Use the code provided in Weeks 5 and 6, and modify as necessary below to calibrate the hydraulic model with regularisation, using the same train data as before."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4caf7e9a",
      "metadata": {
        "id": "4caf7e9a"
      },
      "source": [
        "#### Definition of the regularisation function\n",
        "Ridge regression (l2-regularisation) shrinks parameter estimates (without actually driving them to 0) in the hopes of reducing variance and improving prediction accuracy while lasso regression (-regularisation) encourages sparsity, driving many parameter estimates exactly to zero."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0a34bda",
      "metadata": {
        "id": "e0a34bda"
      },
      "source": [
        "**<u>Question 7:</u>** Based on your answer to Question 6, comment on the expected variance or sparsity pattern of $\\theta$. What type of regularisation (ridge or lasso) term should be included in the objective function of the model calibration problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bfec1a1",
      "metadata": {
        "id": "6bfec1a1"
      },
      "source": [
        "The loss function is defined as:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reg_fun(h, h_data):\n",
        "    return ( 1/len(h_data.flatten()) ) * cp.sum( ( h[sensor_idx, :] - h_data )**2 ) + lambda_0 * cp.norm(theta , 1)"
      ],
      "metadata": {
        "id": "se3hFpqqP3AX"
      },
      "id": "se3hFpqqP3AX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "29de38dd",
      "metadata": {
        "id": "29de38dd"
      },
      "source": [
        "#### Solve the parameter estimation problem using the train dataset\n",
        "Solve the hydraulic model calibration problem with regularisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a91de47e",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "a91de47e"
      },
      "outputs": [],
      "source": [
        "lambda_0 = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unload network training data\n",
        "n_exp = link_df['n_exp']\n",
        "d = data_train['d']\n",
        "h_data = data_train['h_data']\n",
        "h0 = data_train['h0'].reshape(-1, 1).T\n",
        "\n",
        "# define problem parameters\n",
        "Ki = np.inf\n",
        "iter_max = 50\n",
        "delta_k = 400\n",
        "C_up_pipe = 200\n",
        "C_lo_pipe = 1e-4\n",
        "\n",
        "# initialise values\n",
        "theta_k = C_0\n",
        "q_k, h_k = hydraulic_solver(os.path.join(net_dir, net_name), d, h0, C=theta_k)\n",
        "a11_k, b1_k, b2_k = linear_approx_calibration(wdn, q_k, theta_k)\n",
        "objval_k = loss_fun(h_k, h_data).value\n",
        "\n",
        "### main scp code ###\n",
        "for k in range(iter_max):\n",
        "\n",
        "    # decision variables\n",
        "    q = cp.Variable((net_info['np'], nt_train))\n",
        "    h = cp.Variable((net_info['nn'], nt_train))\n",
        "    theta = cp.Variable(net_info['np'])\n",
        "\n",
        "    # objective function (defined using CVXPY functions)\n",
        "    loss = ( 1/len(h_data.flatten()) ) * cp.sum_squares( h[sensor_idx,:] - h_data )\n",
        "    objective = cp.Minimize(loss + lambda_0 * cp.norm((theta - theta_k) , 1))\n",
        "\n",
        "    # hydraulic feasibility constraints\n",
        "    constraints = []\n",
        "    for t in range(nt_train):\n",
        "        # energy and mass constraints\n",
        "        constraints += [\n",
        "            cp.multiply(b1_k[:, t], q_k[:, t]) + cp.multiply(cp.multiply(n_exp, a11_k[:, t]), q[:, t]) + cp.multiply(b2_k[:, t], theta) + A12 @ h[:, t] + A10 @ h0[:, t] == 0,\n",
        "            A12.T @ q[:, t] == d[:, t]\n",
        "        ]\n",
        "\n",
        "    # trust region constraints\n",
        "    constraints += [\n",
        "        cp.norm(theta - theta_k, 'inf') <= delta_k\n",
        "    ]\n",
        "\n",
        "    # variable bounds\n",
        "    lower_bound_pipe = [theta[idx] >= C_lo_pipe for idx, row in link_df.iterrows() if row['link_type'] == 'valve']\n",
        "    constraints += lower_bound_pipe\n",
        "    upper_bound_pipe = [theta[idx] <= C_up_pipe for idx, row in link_df.iterrows() if row['link_type'] == 'valve']\n",
        "    constraints += upper_bound_pipe\n",
        "\n",
        "    # valve minor loss coefficient constraints\n",
        "    valve_constraints = [theta[idx] == C_0[idx] for idx, row in link_df.iterrows() if row['link_type'] == 'pipe']\n",
        "    constraints += valve_constraints\n",
        "\n",
        "    # solve optimisation problem\n",
        "    problem = cp.Problem(objective, constraints)\n",
        "    cvx_val = problem.solve(solver=cp.SCS, verbose=False, max_iters = 1000, eps=1e-3)\n",
        "\n",
        "    # store optimal solution and compute actual and predicted decrease in objval\n",
        "    theta_tilde = theta.value\n",
        "    [q_tilde, h_tilde] = hydraulic_solver(os.path.join(net_dir, net_name), d, h0, C=theta_tilde)\n",
        "    objval_tilde = loss_fun(h_tilde, h_data).value\n",
        "\n",
        "    predicted_decrease = objval_k - cvx_val\n",
        "    actual_decrease = objval_k - objval_tilde\n",
        "\n",
        "    # evaluate latest SCP iteration\n",
        "    if actual_decrease / predicted_decrease >= 0.1:\n",
        "        objval_old = objval_k\n",
        "        theta_k = theta_tilde\n",
        "        q_k = q_tilde\n",
        "        h_k = h_tilde\n",
        "        objval_k = objval_tilde\n",
        "        a11_k, b1_k, b2_k = linear_approx_calibration(wdn, q_k, theta_k)\n",
        "        Ki = np.abs(objval_old - objval_k) / np.abs(objval_old)\n",
        "        delta_k = 1.1 * delta_k\n",
        "        print(f\"Iteration {k} successful! Update estimate and increase trust region size. \\n\")\n",
        "\n",
        "    else:\n",
        "        delta_k = 0.25 * delta_k\n",
        "        print(f\"Iteration {k} unsuccessful! Return to previous estimate and reduce trust region size. \\n\")\n",
        "\n",
        "    print(f\"{k} {objval_k} {Ki} {delta_k} \\n\")\n",
        "\n",
        "    if Ki <= 1e-3 or np.abs(objval_k) <= 1e-2 or delta_k <= 1e-1:\n",
        "        break"
      ],
      "metadata": {
        "id": "p-o4NqQdEQJd"
      },
      "id": "p-o4NqQdEQJd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "75779575",
      "metadata": {
        "id": "75779575"
      },
      "source": [
        "Store the solution (i.e. new coefficients `theta_k`) as $C_2$."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.065e-02"
      ],
      "metadata": {
        "id": "Nj_gt0CHf2sd"
      },
      "id": "Nj_gt0CHf2sd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "307f59ab",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "307f59ab"
      },
      "outputs": [],
      "source": [
        "C_2 = theta_k\n",
        "print(C_2)\n",
        "q_2, h_2 = hydraulic_solver(wdn, d, h0, C=C_2)\n",
        "fk_2 = np.mean((h_2[sensor_idx, :] - h_data) ** 2)\n",
        "print(fk_2)\n",
        "\n",
        "q_test_2, h_test_2 = hydraulic_solver(wdn, data_test['d'], data_test['h0'], C=C_2)\n",
        "mse_test_2 = np.mean((h_test_2[sensor_idx,: ] - data_test['h_data']) ** 2)\n",
        "print(f\"\\n测试集均方误差 (MSE): {mse_test_2:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_residuals_2 =  data_test['h_data'] - h_test_2[sensor_idx,:]\n",
        "\n",
        "print(\"Residuals shape:\", h_residuals_2.shape)\n",
        "mean_residuals_2 = np.mean(h_residuals_2, axis=1)\n",
        "plot_network(wdn, sensor_idx, vals=mean_residuals_2)"
      ],
      "metadata": {
        "id": "NKfw7JZ8VvEU"
      },
      "id": "NKfw7JZ8VvEU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7efc0dd8",
      "metadata": {
        "id": "7efc0dd8"
      },
      "source": [
        "Evaluate final model error and visualise head residuals corresponding to *test* dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "time_points = np.arange(data_test['h_data'].shape[1])  # Create a time index\n",
        "\n",
        "sensor_labels = {sensor: str(idx+1) for idx, sensor in enumerate(sensor_idx)}\n",
        "\n",
        "for i, sensor in enumerate(sensor_idx):\n",
        "    plt.plot(time_points, h_residuals_2[i], label=f\"Sensor {sensor_labels[sensor]}\")\n",
        "\n",
        "plt.axhline(0, color='black', linestyle='--', alpha=0.7)\n",
        "plt.xlabel(\"Time (hours)\")\n",
        "plt.ylabel(\"Pressure Residuals (m)\")\n",
        "plt.title(\"Pressure Residuals Over Time\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qauXZIuPWCGe"
      },
      "id": "qauXZIuPWCGe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f93f12ba",
      "metadata": {
        "id": "f93f12ba"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unload network training data\n",
        "n_exp = link_df['n_exp'].to_numpy().reshape(-1, 1)\n",
        "d = data_train['d']\n",
        "h_data = data_train['h_data']\n",
        "h0 = data_train['h0'].reshape(-1, 1).T\n",
        "\n",
        "# define SCP problem parameters\n",
        "Ki = np.inf\n",
        "iter_max = 50\n",
        "delta_k = 90\n",
        "C_up_pipe = 200\n",
        "C_lo_pipe = 1e-4\n",
        "\n",
        "#initialise values\n",
        "theta_k = C_0\n",
        "q_k, h_k = hydraulic_solver(wdn, d, h0, C=theta_k)\n",
        "a11_k, b1_k, b2_k = linear_approx_calibration(wdn, q_k, theta_k)\n",
        "objval_k = loss_fun(h_k, h_data).value\n",
        "N = np.diag(n_exp.flatten())\n",
        "### main scp code ###\n",
        "for k in range(iter_max):\n",
        "    # 构造凸优化问题\n",
        "    theta = cp.Variable(len(theta_k))\n",
        "    h_expr = cp.Variable((h_k.shape[0],h_k.shape[1]))  # Variable for head\n",
        "    q_expr = cp.Variable((q_k.shape[0],q_k.shape[1]))  # Variable for flow\n",
        "    objective = loss_fun(h_expr, h_data) + lambda_0 * cp.norm(theta_k - theta  , 1)\n",
        "\n",
        "\n",
        "    constraints = []\n",
        "\n",
        "    for t in range(24):\n",
        "        constraints += [\n",
        "        # energy and mass constraints\n",
        "\n",
        "            cp.diag(b1_k[:,i]) @ q_k[:,i] + N @ cp.diag(a11_k[:,i]) @ q_expr[:,i] + cp.diag(b2_k[:,i]) @ theta + A12 @ h_expr[:,i] + A10 @ h0[:,i] == 0,\n",
        "            # 流量平衡约束\n",
        "            A21 @ q_expr[:,i] == d[:,i],\n",
        "\n",
        "    ]\n",
        "    # variable bounds\n",
        "    lower_bound_pipe = [theta[idx] >= C_lo_pipe for idx, row in link_df.iterrows() if row['link_type'] == 'valve']\n",
        "    constraints += lower_bound_pipe\n",
        "    upper_bound_pipe = [theta[idx] <= C_up_pipe for idx, row in link_df.iterrows() if row['link_type'] == 'valve']\n",
        "    constraints += upper_bound_pipe\n",
        "\n",
        "    # valve minor loss coefficient constraints\n",
        "    valve_constraints = [theta[idx] == C_0[idx] for idx, row in link_df.iterrows() if row['link_type'] == 'pipe']\n",
        "    constraints += valve_constraints\n",
        "    constraints +=[\n",
        "            # 信任域约束\n",
        "        cp.norm( theta - theta_k , 'inf') <= delta_k\n",
        "    ]\n",
        "    problem = cp.Problem(cp.Minimize(objective), constraints)\n",
        "    cvx_val = problem.solve(solver=cp.SCS, eps=1e-3 ,max_iters=1000, verbose=False)\n",
        "\n",
        "    # 获取候选解\n",
        "    theta_candidate = theta.value\n",
        "    if theta_candidate is None:\n",
        "        delta_k *= 0.2\n",
        "        continue\n",
        "    [q_candidate,  h_candidate] =   hydraulic_solver(wdn, d, h0, C=theta_candidate)\n",
        "    objval_candidate = loss_fun(h_candidate, h_data).value\n",
        "\n",
        "    denominator = objval_k - problem.value\n",
        "    if abs(denominator) < 1e-10:\n",
        "       rho = 0  # 视为无改进\n",
        "    else:\n",
        "       rho = (objval_k - objval_candidate) / denominator\n",
        "\n",
        "\n",
        "    # 信任域调整逻辑\n",
        "    if rho >= 0.1:\n",
        "        # 接受新解\n",
        "        Ki = np.abs(objval_k - objval_candidate) / abs(objval_k)\n",
        "        theta_k = theta_candidate.copy()\n",
        "        q_k = q_candidate.copy()\n",
        "        h_k = h_candidate.copy()\n",
        "        objval_k = objval_candidate\n",
        "        delta_k = 1.1 * delta_k\n",
        "        print(f\"Iteration {k} successful! Update estimate and increase trust region size. \\n\")\n",
        "        # 更新线性化矩阵\n",
        "        a11_k, b1_k, b2_k = linear_approx_calibration(wdn, q_k, theta_k)\n",
        "    else:\n",
        "        # 拒绝新解\n",
        "        delta_k = 0.25 * delta_k\n",
        "        print(f\"Iteration {k} unsuccessful!{objval_k} Return to previous estimate and reduce trust region size{delta_k}. \\n\")\n",
        "\n",
        "    if  Ki<=1e-3 or delta_k <= 1e-4:\n",
        "        print(f\"第{k+1}次完成迭代\")\n",
        "        break"
      ],
      "metadata": {
        "id": "61rERqaSKFOy",
        "outputId": "c63606cb-ab01-44aa-d589-7de5305a566c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "61rERqaSKFOy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 unsuccessful!9.705414431633923 Return to previous estimate and reduce trust region size22.5. \n",
            "\n",
            "Iteration 1 unsuccessful!9.705414431633923 Return to previous estimate and reduce trust region size5.625. \n",
            "\n",
            "Iteration 2 unsuccessful!9.705414431633923 Return to previous estimate and reduce trust region size1.40625. \n",
            "\n",
            "Iteration 3 unsuccessful!9.705414431633923 Return to previous estimate and reduce trust region size0.3515625. \n",
            "\n",
            "Iteration 4 unsuccessful!9.705414431633923 Return to previous estimate and reduce trust region size0.087890625. \n",
            "\n",
            "Iteration 5 unsuccessful!9.705414431633923 Return to previous estimate and reduce trust region size0.02197265625. \n",
            "\n",
            "Iteration 6 unsuccessful!9.705414431633923 Return to previous estimate and reduce trust region size0.0054931640625. \n",
            "\n",
            "Iteration 7 unsuccessful!9.705414431633923 Return to previous estimate and reduce trust region size0.001373291015625. \n",
            "\n",
            "Iteration 8 unsuccessful!9.705414431633923 Return to previous estimate and reduce trust region size0.00034332275390625. \n",
            "\n",
            "Iteration 9 unsuccessful!9.705414431633923 Return to previous estimate and reduce trust region size8.58306884765625e-05. \n",
            "\n",
            "第10次完成迭代\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19479f6e",
      "metadata": {
        "id": "19479f6e"
      },
      "source": [
        "**<u>Question 8:</u>** Comment on the improvement in model accuracy after calibration with regularisation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60e1ab70",
      "metadata": {
        "id": "60e1ab70"
      },
      "source": [
        "#### Discuss the values of the calibrated coefficients $C_2$\n",
        "Visualise the values of newly calibrated coefficients $C_2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1887a110",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "1887a110"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e31cc828",
      "metadata": {
        "id": "e31cc828"
      },
      "source": [
        "**<u>Question 9:</u>** Comment on the values of parameter estimates in $C_2$ compared to $C_1$ and explain the results of the calibration with regularisation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d827c982",
      "metadata": {
        "id": "d827c982"
      },
      "source": [
        "**<u>Question 10:</u>** Do the calibrated local loss coefficient values in $C_2$ corroborate the conclusions of the preliminary analysis about the most likely sources of error in the EXNING model (existence/location of unknowingly closed valves)? Summarise your findings (100-150 words + 1-2 figures) and provide recommendations to AW to validate your proposed hydraulic model update.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unload network training data\n",
        "n_exp = link_df['n_exp'].to_numpy().reshape(-1, 1)\n",
        "d = data_train['d']\n",
        "h_data = data_train['h_data']\n",
        "h0 = data_train['h0'].reshape(-1, 1).T\n",
        "\n",
        "# define SCP problem parameters\n",
        "Ki = np.inf\n",
        "iter_max = 50\n",
        "delta_k = 120\n",
        "C_up_pipe = 200\n",
        "C_lo_pipe = 1e-4\n",
        "\n",
        "#initialise values\n",
        "theta_k = C_0\n",
        "q_k, h_k = hydraulic_solver(wdn, d, h0, C=theta_k)\n",
        "a11_k, b1_k, b2_k = linear_approx_calibration(wdn, q_k, theta_k)\n",
        "objval_k = loss_fun(h_k, h_data).value\n",
        "N = np.diag(n_exp.flatten())\n",
        "### main scp code ###\n",
        "for k in range(iter_max):\n",
        "    # 构造凸优化问题\n",
        "    theta = cp.Variable(len(theta_k))\n",
        "    h = cp.Variable((h_k.shape[0],h_k.shape[1]))  # Variable for head\n",
        "    q = cp.Variable((q_k.shape[0],q_k.shape[1]))  # Variable for flow\n",
        "    objective = loss_fun(h, h_data)\n",
        "\n",
        "\n",
        "    constraints = []\n",
        "\n",
        "    for i in range(24):\n",
        "        constraints += [\n",
        "        # energy and mass constraints\n",
        "\n",
        "             cp.diag(b1_k[:,i]) @ q_k[:,i] + N @ cp.diag(a11_k[:,i]) @ q[:,i] + cp.diag(b2_k[:,i]) @ theta + A12 @ h[:,i] + A10 @ h0[:,i] == 0,\n",
        "             #流量平衡约束\n",
        "            A21 @ q[:,i] == d[:,i],\n",
        "\n",
        "    ]\n",
        "    #for t in range(24):\n",
        "        # energy and mass constraints\n",
        "        #constraints += [\n",
        "            #cp.multiply(cp.diag(b1_k[:, t]), q_k[:, t]) + cp.multiply(cp.multiply(cp.diag(n_exp), np.diag(a11_k[:, t])), q[:, t]) + cp.multiply(cp.diag(b2_k[:, t]), theta) + A12 @ h[:, t] + A10 @ h0[:, t] == 0,\n",
        "            #A12.T @ q[:, t] == d[:, t]\n",
        "      #  ]\n",
        "    # variable bounds\n",
        "    lower_bound_pipe = [theta[idx] >= C_lo_pipe for idx, row in link_df.iterrows() if row['link_type'] == 'valve']\n",
        "    constraints += lower_bound_pipe\n",
        "    upper_bound_pipe = [theta[idx] <= C_up_pipe for idx, row in link_df.iterrows() if row['link_type'] == 'valve']\n",
        "    constraints += upper_bound_pipe\n",
        "\n",
        "    # valve minor loss coefficient constraints\n",
        "    valve_constraints = [theta[idx] == C_0[idx] for idx, row in link_df.iterrows() if row['link_type'] == 'pipe']\n",
        "    constraints += valve_constraints\n",
        "    constraints +=[\n",
        "            # 信任域约束\n",
        "        cp.norm( theta - theta_k , 'inf') <= delta_k\n",
        "    ]\n",
        "    problem = cp.Problem(cp.Minimize(objective), constraints)\n",
        "    cvx_val = problem.solve(solver=cp.SCS ,max_iters=1000, verbose=False)\n",
        "\n",
        "    # 获取候选解\n",
        "    theta_candidate = theta.value\n",
        "    if theta_candidate is None:\n",
        "        delta_k *= 0.2\n",
        "        continue\n",
        "    [q_candidate,  h_candidate] =   hydraulic_solver(wdn, d, h0, C=theta_candidate)\n",
        "    objval_candidate = loss_fun(h_candidate, h_data).value\n",
        "\n",
        "    denominator = objval_k - problem.value\n",
        "    if abs(denominator) < 1e-10:\n",
        "       rho = 0  # 视为无改进\n",
        "    else:\n",
        "       rho = (objval_k - objval_candidate) / denominator\n",
        "\n",
        "\n",
        "    # 信任域调整逻辑\n",
        "    if rho >= 0.1:\n",
        "        # 接受新解\n",
        "        Ki = np.abs(objval_k - objval_candidate) / abs(objval_k)\n",
        "        theta_k = theta_candidate.copy()\n",
        "        q_k = q_candidate.copy()\n",
        "        h_k = h_candidate.copy()\n",
        "        objval_k = objval_candidate\n",
        "        delta_k = 1.1 * delta_k\n",
        "        print(f\"Iteration {k} successful! Update estimate and increase trust region size. \\n\")\n",
        "        # 更新线性化矩阵\n",
        "        a11_k, b1_k, b2_k = linear_approx_calibration(wdn, q_k, theta_k)\n",
        "    else:\n",
        "        # 拒绝新解\n",
        "        delta_k = 0.25 * delta_k\n",
        "        print(f\"Iteration {k} unsuccessful!{objval_k} Return to previous estimate and reduce trust region size{delta_k}. \\n\")\n",
        "\n",
        "    if  Ki<=1e-3 or delta_k <= 1e-3:\n",
        "        print(f\"第{k+1}次完成迭代\")\n",
        "        break\n"
      ],
      "metadata": {
        "id": "fx96uuYVw6W5"
      },
      "id": "fx96uuYVw6W5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "608d9096",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "608d9096",
        "outputId": "95de2d63-2d59-41d2-e828-b837922b15b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure:interrupted\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SolverError",
          "evalue": "Solver 'SCS' failed. Try another solver, or solve with verbose=True for more information.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSolverError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-217-805b2397fac0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     ]\n\u001b[1;32m     47\u001b[0m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProblem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMinimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSCS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# 获取候选解\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m                     \"Cannot specify both 'solver' and 'solver_path'. Please choose one.\")\n\u001b[1;32m    599\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_solver_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolve_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msolver_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msolve_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(self, solver, warm_start, verbose, gp, qcp, requires_grad, enforce_dpp, ignore_dpp, canon_backend, **kwargs)\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolving_chain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_FOOTER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36munpack_results\u001b[0;34m(self, solution, chain, inverse_data)\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINF_OR_UNB_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1512\u001b[0;31m             raise error.SolverError(\n\u001b[0m\u001b[1;32m   1513\u001b[0m                     \u001b[0;34m\"Solver '%s' failed. \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m                     \u001b[0;34m\"Try another solver, or solve with verbose=True for more \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSolverError\u001b[0m: Solver 'SCS' failed. Try another solver, or solve with verbose=True for more information."
          ]
        }
      ],
      "source": [
        "# unload network training data\n",
        "n_exp = link_df['n_exp'].to_numpy().reshape(-1, 1)\n",
        "d = data_train['d']\n",
        "h_data = data_train['h_data']\n",
        "h0 = data_train['h0'].reshape(-1, 1).T\n",
        "\n",
        "# define SCP problem parameters\n",
        "Ki = np.inf\n",
        "iter_max = 50\n",
        "delta_k = 20\n",
        "C_up_pipe = 200\n",
        "C_lo_pipe = 1e-03\n",
        "CHECK=0\n",
        "#initialise values\n",
        "theta_k = link_df['C'].to_numpy()\n",
        "q_k, h_k = hydraulic_solver(wdn, d, h0, C=theta_k)\n",
        "a11_k, b1_k, b2_k = linear_approx_calibration(wdn, q_k, theta_k)\n",
        "fk = np.mean((h_k[sensor_idx, :] - h_data) ** 2)\n",
        "objval_k = loss_fun(h_k, h_data).value\n",
        "### main scp code ###\n",
        "for k in range(iter_max):\n",
        "    # 构造凸优化问题\n",
        "    theta = cp.Variable(len(theta_k))\n",
        "    h_expr = cp.Variable((h_k.shape[0],h_k.shape[1]))  # Variable for head\n",
        "    q_expr = cp.Variable((q_k.shape[0],q_k.shape[1]))  # Variable for flow\n",
        "    objective = loss_fun(h_expr, h_data) + lambda_0 * cp.norm(theta , 1)\n",
        "\n",
        "\n",
        "    constraints = []\n",
        "\n",
        "    for i in range(24):\n",
        "        constraints += [\n",
        "        # 线性化后的能量守恒方程\n",
        "\n",
        "            cp.diag(b1_k[:,i]) @ q_k[:,i] + N @ cp.diag(a11_k[:,i]) @ q_expr[:,i] + cp.diag(b2_k[:,i]) @ theta + A12 @ h_expr[:,i] + A10 @ h0[:,i] == 0,\n",
        "            # 流量平衡约束\n",
        "            A21 @ q_expr[:,i] == d[:,i],\n",
        "\n",
        "    ]\n",
        "    constraints +=[\n",
        "         # 参数上下限\n",
        "        theta >= C_lo_pipe,\n",
        "        theta <= C_up_pipe,\n",
        "            # 信任域约束\n",
        "        cp.norm( theta - theta_k , 'inf') <= delta_k\n",
        "    ]\n",
        "    prob = cp.Problem(cp.Minimize(objective), constraints)\n",
        "    prob.solve(solver = cp.SCS,eps=1e-6,max_iters=5000, verbose=False)\n",
        "\n",
        "    # 获取候选解\n",
        "    theta_candidate = theta.value\n",
        "    if theta_candidate is None:\n",
        "        delta_k *= 0.5\n",
        "        continue\n",
        "    q_candidate,  h_candidate =   hydraulic_solver(wdn, d, h0, C=theta_candidate)\n",
        "    objval_candidate = loss_fun(h_candidate, h_data).value + lambda_0 * cp.norm(theta_candidate , 1).value\n",
        "\n",
        "    denominator = objval_k - prob.value\n",
        "    if abs(denominator) < 1e-10:\n",
        "      rho = 0  # 视为无改进\n",
        "    else:\n",
        "       rho = (objval_k - objval_candidate) / denominator\n",
        "\n",
        "\n",
        "    # 信任域调整逻辑\n",
        "    if rho >= 0.01:\n",
        "        # 接受新解\n",
        "        Ki = abs(objval_k - objval_candidate) / abs(objval_k)\n",
        "        theta_k = theta_candidate.copy()\n",
        "        q_k = q_candidate.copy()\n",
        "        h_k = h_candidate.copy()\n",
        "        objval_k = loss_fun(h_k, h_data).value + lambda_0 * cp.norm(theta_k , 1).value\n",
        "        delta_k = 1.1 * delta_k\n",
        "\n",
        "        # 更新线性化矩阵\n",
        "        a11_k, b1_k, b2_k = linear_approx_calibration(wdn, q_k, theta_k)\n",
        "    else:\n",
        "        # 拒绝新解\n",
        "        delta_k = 0.5 * delta_k\n",
        "\n",
        "\n",
        "    if  Ki<=1e-3 or delta_k <= 1e-4:\n",
        "        print(f\"第{k+1}次完成迭代\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unload network training data\n",
        "n_exp = link_df['n_exp'].to_numpy().reshape(-1, 1)\n",
        "d = data_train['d']\n",
        "h_data = data_train['h_data']\n",
        "h0 = data_train['h0'].reshape(-1, 1).T\n",
        "\n",
        "# define SCP problem parameters\n",
        "Ki = np.inf\n",
        "iter_max = 50\n",
        "delta_k = 25\n",
        "C_up_pipe = 200\n",
        "C_lo_pipe = 1.1e-4\n",
        "CHECK=0\n",
        "#initialise values\n",
        "theta_k = link_df['C'].to_numpy()\n",
        "q_k, h_k = hydraulic_solver(wdn, d, h0, C=theta_k)\n",
        "a11_k, b1_k, b2_k = linear_approx_calibration(wdn, q_k, theta_k)\n",
        "fk = np.mean((h_k[sensor_idx, :] - h_data) ** 2)\n",
        "objval_k = loss_fun(h_k, h_data).value\n",
        "N = np.diag(n_exp.flatten())\n",
        "### main scp code ###\n",
        "for k in range(iter_max):\n",
        "    # 构造凸优化问题\n",
        "    theta = cp.Variable(len(theta_k))\n",
        "    h_expr = cp.Variable((h_k.shape[0],h_k.shape[1]))  # Variable for head\n",
        "    q_expr = cp.Variable((q_k.shape[0],q_k.shape[1]))  # Variable for flow\n",
        "    objective = loss_fun(h_expr, h_data)\n",
        "\n",
        "\n",
        "    constraints = []\n",
        "\n",
        "    for i in range(24):\n",
        "        constraints += [\n",
        "        # 线性化后的能量守恒方程\n",
        "\n",
        "            cp.diag(b1_k[:,i]) @ q_k[:,i] + N @ cp.diag(a11_k[:,i]) @ q_expr[:,i] + cp.diag(b2_k[:,i]) @ theta + A12 @ h_expr[:,i] + A10 @ h0[:,i] == 0,\n",
        "            # 流量平衡约束\n",
        "            A21 @ q_expr[:,i] == d[:,i],\n",
        "\n",
        "    ]\n",
        "    constraints +=[\n",
        "         # 参数上下限\n",
        "        theta >= C_lo_pipe,\n",
        "        theta <= C_up_pipe,\n",
        "            # 信任域约束\n",
        "        cp.norm( theta - theta_k , 'inf') <= delta_k\n",
        "    ]\n",
        "    prob = cp.Problem(cp.Minimize(objective), constraints)\n",
        "    prob.solve(solver = cp.SCS,eps=1e-6,max_iters=5000, verbose=False)\n",
        "\n",
        "    # 获取候选解\n",
        "    theta_candidate = theta.value\n",
        "    if theta_candidate is None:\n",
        "        delta_k *= 0.5\n",
        "        continue\n",
        "    q_candidate,  h_candidate =   hydraulic_solver(wdn, d, h0, C=theta_candidate)\n",
        "    objval_candidate = loss_fun(h_candidate, h_data).value\n",
        "\n",
        "    denominator = objval_k - prob.value\n",
        "    if abs(denominator) < 1e-10:\n",
        "      rho = 0  # 视为无改进\n",
        "    else:\n",
        "       rho = (objval_k - objval_candidate) / denominator\n",
        "\n",
        "\n",
        "    # 信任域调整逻辑\n",
        "    if rho >= 0.01:\n",
        "        # 接受新解\n",
        "        Ki = abs(objval_k - objval_candidate) / abs(objval_k)\n",
        "        theta_k = theta_candidate.copy()\n",
        "        q_k = q_candidate.copy()\n",
        "        h_k = h_candidate.copy()\n",
        "        objval_k = loss_fun(h_k, h_data).value\n",
        "        delta_k = 1.2 * delta_k\n",
        "\n",
        "        # 更新线性化矩阵\n",
        "        a11_k, b1_k, b2_k = linear_approx_calibration(wdn, q_k, theta_k)\n",
        "    else:\n",
        "        # 拒绝新解\n",
        "        delta_k = 0.6 * delta_k\n",
        "\n",
        "\n",
        "    if  Ki<=1e-3 or delta_k <= 1e-4:\n",
        "        print(f\"第{k+1}次完成迭代\")\n",
        "        break\n"
      ],
      "metadata": {
        "id": "5OcUZvloUxFK"
      },
      "id": "5OcUZvloUxFK",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}